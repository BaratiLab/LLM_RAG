# Llama2 RAG System with Hugging Face

This repository contains a Jupyter Notebook that demonstrates the implementation of a Retrieval-Augmented Generation (RAG) system using the Llama2 model through the Hugging Face platform. The .py file is the RAG implementation with a Graphical User Interface (GUI) using the streamlit python library.

## Overview

The notebook provides an example of setting up a RAG system which utilizes Llama2 for enhancing text generation capabilities with the power of external knowledge retrieval.

## Features

- Implementation of the RAG system using Llama2.
- Integration with Hugging Face libraries.
- Demonstrations of setup and basic usage.

## Requirements

- Python 3.x
- Hugging Face Transformers
- Other dependencies listed in `requirements.txt`

## Setup

1. Clone the repository:
   ```bash
   git clone <repository-url>
   ```

2. Create a conda environment:
   '''bash
   conda create -n myenv python=3.x
   '''

3. Install the required packages:
   ```bash
   pip install -r requirements.txt
   ```

4. Activate your environemt:
   ```bash
   conda activate myenv
   ```
5. Open the notebook in Jupyter Lab or Jupyter Notebook:
   ```bash
   jupyter lab
   ```

## Usage

Follow the instructions in the notebook to learn how to initialize the system, prepare data, and generate responses using the RAG model.

## Running the .py file

1. Create a conda environment:
   '''bash
   conda create -n myenv python=3.9
   '''

2. Activate your environemt:
   ```bash
   conda activate #######
   ```
3. Run Streamlit:
   ```bash
   streamlit run llama_app.py
   ```

## Contributing

Contributions are welcome! For major changes, please open an issue first to discuss what you would like to change.

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.
